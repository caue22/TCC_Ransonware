
# Ransomware: A ProblemÃ¡tica do Ataque e o Impacto do Balanceamento de Dados em Algoritmos de ClassificaÃ§Ã£o de Ataques

Este repositÃ³rio reÃºne o **Trabalho de ConclusÃ£o de Curso (TCC)** de **CauÃª Garcia Nascimento** e **Felipe Ribeiro de Rezende**, apresentado ao **Instituto Federal Goiano â€“ Campus UrutaÃ­**, no curso de **Sistemas de InformaÃ§Ã£o**, sob orientaÃ§Ã£o do **Prof. Dr. Gabriel da Silva Vieira**.

O estudo investiga o **impacto do balanceamento de dados** na detecÃ§Ã£o de **ataques de ransomware** por meio de **algoritmos de machine learning**, utilizando os classificadores **Random Forest** e **Decision Tree**.

---

## ğŸ“ Estrutura do RepositÃ³rio

```
â”œâ”€â”€ ğŸ“„ tcc_Caue_Garcia_Felipe_Rezende.pdf        # Trabalho completo em PDF
â””â”€â”€ ğŸ“‚ notebooks/
    â”œâ”€â”€ ğŸ“‚ dataset_balanceado/
    â”‚   â””â”€â”€ Dataset_balanceado_com_undersampling.ipynb  # CriaÃ§Ã£o do dataset balanceado
    â”‚
    â”œâ”€â”€ ğŸ“‚ treinamentos/
    â”‚   â”œâ”€â”€ Treinando_Modelo_Decision_Tree_Desbalanceado.ipynb
    â”‚   â”œâ”€â”€ Treinando_Modelo_Random_Forest_Desbalanceado.ipynb
    â”‚   â”œâ”€â”€ Treinando_Modelo_Decision_Tree_Balanceado.ipynb
    â”‚   â””â”€â”€ Treinando_Modelo_Random_Forest_Balanceado.ipynb
    â”‚
    â””â”€â”€ ğŸ“‚ uso_modelos/
        â”œâ”€â”€ Usando_Modelo_Treinado_Decision_Tree_Desbalanceado.ipynb
        â”œâ”€â”€ Usando_Modelo_Treinado_Random_Forest_Desbalanceado.ipynb
        â”œâ”€â”€ Usando_Modelo_Treinado_Decision_Tree_Balanceado.ipynb
        â””â”€â”€ Usando_Modelo_Treinado_Random_Forest_Balanceado.ipynb
```

ğŸ“Œ *A estrutura foi separada para tornar o fluxo do projeto mais claro: primeiro gera-se o dataset balanceado (caso necessÃ¡rio), depois treina-se os modelos e, por fim, executa-se os notebooks de uso/anÃ¡lise.*

---

## ğŸš€ ExecuÃ§Ã£o dos Algoritmos no Google Colab

Os notebooks estÃ£o prontos para serem executados diretamente no **Google Colab**, sem necessidade de instalaÃ§Ã£o local.

### ğŸ‘‰ Passo a passo geral

1. **Acesse o repositÃ³rio** no GitHub.

2. Abra o notebook desejado (`.ipynb`).

3. Clique no botÃ£o **â€œOpen in Colabâ€** (ou adicione manualmente o prefixo abaixo ao link do arquivo):

   ```
   https://colab.research.google.com/github/<seu_usuario>/<seu_repositorio>/blob/main/caminho/do/notebook.ipynb
   ```

4. **Monte seu Google Drive** dentro do Colab, executando o trecho:

   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   ```

5. **Execute as cÃ©lulas sequencialmente** para reproduzir o treinamento e a avaliaÃ§Ã£o dos modelos.

---

## ğŸ’¾ PrÃ©-requisitos Importantes

Para executar os notebooks corretamente, Ã© necessÃ¡rio:

1. Ter uma **conta Google ativa**, pois o **Google Colab** e o **Google Drive** sÃ£o utilizados para armazenar e carregar datasets e modelos.
2. Garantir que os arquivos gerados (modelos e datasets) sejam salvos no **seu Google Drive**, conforme indicado no cÃ³digo dos notebooks.
3. Executar as cÃ©lulas de **montagem do Google Drive** sempre que abrir um novo notebook, para que os arquivos possam ser lidos e gravados corretamente.

---

## ğŸ§© Fluxo de ExecuÃ§Ã£o dos Modelos

O projeto Ã© dividido em **dois fluxos principais**:
â¡ï¸ **Modelos desbalanceados** e
â¡ï¸ **Modelos balanceados (com undersampling)**.

Abaixo estÃ¡ o passo a passo completo para cada caso:

---

### ğŸ”¹ **Modelos Desbalanceados**

1. Execute primeiro o notebook de **treinamento** (usando o dataset original):

   * [Treinando_Modelo_Decision_Tree_Desbalanceado.ipynb](notebooks/treinamentos/Treinando_Modelo_Decision_Tree_Desbalanceado.ipynb)
   * [Treinando_Modelo_Random_Forest_Desbalanceado.ipynb](notebooks/treinamentos/Treinando_Modelo_Random_Forest_Desbalanceado.ipynb)

2. Os modelos sÃ£o treinados diretamente com o **dataset original (sem balanceamento)**.

3. ApÃ³s o treinamento, os arquivos do modelo sÃ£o **salvos automaticamente no Google Drive**.

4. Em seguida, execute os notebooks de **uso e anÃ¡lise dos modelos treinados**:

   * [Usando_Modelo_Treinado_Decision_Tree_Desbalanceado.ipynb](notebooks/uso_modelos/Usando_Modelo_Treinado_Decision_Tree_Desbalanceado.ipynb)
   * [Usando_Modelo_Treinado_Random_Forest_Desbalanceado.ipynb](notebooks/uso_modelos/Usando_Modelo_Treinado_Random_Forest_Desbalanceado.ipynb)

---

### ğŸ”¹ **Modelos Balanceados (com Undersampling)**

1. Antes de treinar qualquer modelo balanceado, execute o notebook responsÃ¡vel por criar o dataset balanceado:

   * [Dataset_balanceado_com_undersampling.ipynb](notebooks/dataset_balanceado/Dataset_balanceado_com_undersampling.ipynb)

   Esse notebook aplica a tÃ©cnica de **undersampling**, gerando um novo dataset equilibrado e salvo no Google Drive.

2. ApÃ³s a geraÃ§Ã£o do dataset balanceado, execute os notebooks de **treinamento dos modelos**:

   * [Treinando_Modelo_Decision_Tree_Balanceado.ipynb](notebooks/treinamentos/Treinando_Modelo_Decision_Tree_Balanceado.ipynb)
   * [Treinando_Modelo_Random_Forest_Balanceado.ipynb](notebooks/treinamentos/Treinando_Modelo_Random_Forest_Balanceado.ipynb)

3. Os modelos treinados serÃ£o salvos no Google Drive.
   Depois, rode os notebooks de **uso e anÃ¡lise**:

   * [Usando_Modelo_Treinado_Decision_Tree_Balanceado.ipynb](notebooks/uso_modelos/Usando_Modelo_Treinado_Decision_Tree_Balanceado.ipynb)
   * [Usando_Modelo_Treinado_Random_Forest_Balanceado.ipynb](notebooks/uso_modelos/Usando_Modelo_Treinado_Random_Forest_Balanceado.ipynb)

ğŸ’¡ **Importante:** o dataset balanceado precisa ser criado **apenas uma vez** â€” depois disso, os notebooks de treinamento podem utilizÃ¡-lo diretamente.

---

## ğŸ§  Objetivos do Trabalho

* Analisar o **impacto do balanceamento de dados** (usando undersampling) no desempenho dos modelos de classificaÃ§Ã£o.
* Avaliar as diferenÃ§as entre datasets **balanceados e desbalanceados** na detecÃ§Ã£o de **ransomware**.
* Comparar os resultados das mÃ©tricas **Precision**, **Recall**, **F1-Score** e **AUC-ROC**.

---

## ğŸ“Š Resultados Principais

* O modelo **Random Forest** apresentou melhor desempenho geral, com **AUC-ROC superior a 99%**.
* O **balanceamento de dados** proporcionou uma **distribuiÃ§Ã£o mais justa dos acertos** entre as classes (`E = Encrypter`, `L = Locker`, `G = Goodware`).
* Os modelos desbalanceados mostraram **tendÃªncia a favorecer classes majoritÃ¡rias**, impactando a detecÃ§Ã£o de ataques menos frequentes.

---

## ğŸ§© Principais Tecnologias Utilizadas

* **Python 3.10**
* **Google Colab**
* **Pandas**
* **Scikit-Learn**
* **Matplotlib / Seaborn**
* **NumPy**

---

## ğŸ‘¨â€ğŸ’» Autores

<p>
    <img 
      align=left 
      margin=10 
      width=80 
      src="https://avatars.githubusercontent.com/u/115797711?v=4"
    />
    <p>&nbsp&nbsp&nbspCauÃª Garcia Nascimento<br>
    &nbsp&nbsp&nbsp
    <a href="https://github.com/caue22">GitHub</a>&nbsp;|&nbsp;
    <a href="https://www.linkedin.com/in/cau%C3%AA-garcia-nascimento-436a14213">LinkedIn</a>

</p>
<br/><br/>
<p>
    <img 
      align=left 
      margin=10 
      width=80 
      src="https://avatars.githubusercontent.com/u/106535940?v=4"
    />
    <p>&nbsp&nbsp&nbspFelipe Ribeiro de Rezende<br>
    &nbsp&nbsp&nbsp
    <a href="https://github.com/eufrezende">GitHub</a>&nbsp;|&nbsp;
    <a href="https://www.linkedin.com/in/feliperrezende/">LinkedIn</a>

</p>

---

## ğŸ« InstituiÃ§Ã£o

**Instituto Federal Goiano â€“ Campus UrutaÃ­**

Curso de **Bacharelado em Sistemas de InformaÃ§Ã£o**

Orientador: **Prof. Dr. Gabriel da Silva Vieira**